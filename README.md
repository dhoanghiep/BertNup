# BertNup

**BertNup: A Transformer-Based Model for Nucleosome Positioning Prediction**

This is the repository for the implementation of BertNup.

---

### Dependencies
- Python 3.9 or above
- pandas
- numpy
- scikit-learn
- matplotlib
- biopython
- torch
- transformers
- pytorch-lightning

### Data
- Raw data is provided in the `Data` directory.
- To generate preprocessed data for model training, run `data_preparation.ipynb`.

### Fine-tuning
- To fine-tune based on a pre-trained model, run `fine-tuning.ipynb`.

### K-fold Cross Validation
- To perform k-fold cross-validation, run `kfold_cross_validation.ipynb`.

### Attention Score Visualization
- All visualizations related to attention scores can be generated by running `attention_visualization.ipynb`.
- An example fine-tuned model based on DNABERT-1-3 can be downloaded from Google Drive: https://drive.google.com/file/d/1yz-nZ45CHNqOTbMVnuZys36Fp9Xj-NLN/view?usp=sharing.